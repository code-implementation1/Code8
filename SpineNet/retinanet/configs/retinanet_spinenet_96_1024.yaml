# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: 0
data_url: ''
train_url: '/cache/data/retinanet_models'
checkpoint_url: ''
data_path: '/cache/data'
output_path: '/cache/train'
load_path: '/cache/checkpoint_path'
enable_profiling: 0

train_outputs: '/data/retinanet_models'
brief: 'gpu-1'
device_target: GPU
mode: 'graph'
# ==============================================================================
detector: 'retinanet'


# backbone
backbone:
  type: 'spinenet'
  arch: '96'
  norm_cfg:
    type: 'BN'
    momentum: 0.01
    eps: 0.001

# dense bbox head retinanet
bbox_head:
  num_ins: 5
  in_channels: 256
  stacked_convs: 4
  feat_channels: 256
  bbox_coder:
    target_means: [.0, .0, .0, .0]
    target_stds: [1.0, 1.0, 1.0, 1.0]
  loss_cls:
    gamma: 2.0
    alpha: 0.25
    loss_weight: 1.0
  loss_bbox:
    beta: 0.11
    loss_weight: 1.0
  anchor_generator:
    octave_base_scale: 3
    scales_per_octave: 3
    ratios: [0.5, 1.0, 2.0]
    strides: [8, 16, 32, 64, 128]
  norm_cfg:
    type: 'BN'
    momentum: 0.01
    eps: 0.001

train_cfg:
  assigner:
    pos_iou_thr: 0.5
    neg_iou_thr: 0.5
    min_pos_iou: 0.00001
    match_low_quality: True

test_cfg:
  nms_pre: 1000
  min_bbox_size: 0
  score_thr: 0.05
  max_per_img: 100
  nms:
    iou_threshold: 0.5

# optimizer
opt_type: 'sgd'
lr: 0.14
min_lr: 0.0000001
momentum: 0.9
weight_decay: 0.00004
warmup_step: 4000
warmup_ratio: 0.1
lr_steps: [320, 340]
lr_type: 'multistep'
grad_clip: 0


# train
num_gts: 100
batch_size: 2
accumulate_step: 1
test_batch_size: 1
loss_scale: 256
epoch_size: 350
run_eval: 1
eval_every: 1
enable_graph_kernel: 0
finetune: 0
datasink: 0
pre_trained: ''

#distribution training
run_distribute: 0
device_id: 0
device_num: 1
rank_id: 0

# Number of threads used to process the dataset in parallel
num_parallel_workers: 6
# Parallelize Python operations with multiple worker processes
python_multiprocessing: 0
# dataset setting
train_dataset: '/data/coco-2017/train'
val_dataset: '/data/coco-2017/validation/'
coco_classes: ['background', 'person', 'bicycle', 'car', 'motorcycle',
               'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']
num_classes: 81
train_dataset_num: 0
train_dataset_divider: 0

# images
img_width: 1024
img_height: 1024
ratio_range: [0.5, 2.0]
divider: 64
img_mean: [123.675, 116.28, 103.53]
img_std: [58.395, 57.12, 57.375]
to_rgb: 1
keep_ratio: 1

# augmentation
flip_ratio: 0.5
expand_ratio: 0.0

# callbacks
save_every: 100
keep_checkpoint_max: 5
keep_best_checkpoints_max: 5

---
# Config description for each option
enable_modelarts: 'Whether training on modelarts, default: False'

device_target: 'device where the code will be implemented, default is GPU.'
train_outputs: 'Path for folder with experiments.'
brief: 'Short experiment name, experiment folder will arrive in `train_outputs` folder. `brief` will suffix of experiment folder name.'
img_width: 'Input images weight.'
img_height: 'Input images height.'

lr: 'Base learning rate value.'
batch_size: 'Training batch size.'
pre_trained: 'Path to pretraining model (resume training or train new fine tuned model).'

---
device_target: ['GPU', 'CPU']
mode: ['graph', 'pynative']
