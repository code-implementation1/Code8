# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: 0
data_url: ''
train_url: '/cache/data/mask_rcnn_models'
checkpoint_url: ''
data_path: '/cache/data'
output_path: '/cache/train'
load_path: '/cache/checkpoint_path'
enable_profiling: 0

train_outputs: '/data/mask_rcnn_models'
brief: 'gpu-1'
device_target: GPU
mode: 'graph'
# ==============================================================================
detector: 'mask_rcnn'

# backbone
backbone:
  type: 'spinenet'
  arch: '49S'
  norm_cfg:
    type: 'BN'
    momentum: 0.01
    eps: 0.001

# rpn
rpn:
  in_channels: 128
  feat_channels: 128
  num_classes: 1
  bbox_coder:
    # clip_border: True
    target_means: [0., 0., 0., 0.]
    target_stds: [1.0, 1.0, 1.0, 1.0]
  loss_cls:
    loss_weight: 1.0
  loss_bbox:
    loss_weight: 1.0
    beta: 0.111111111111
  anchor_generator:
    scales: [3]
    strides: [8, 16, 32, 64, 128]
    ratios: [0.5, 1.0, 2.0]

bbox_head:
  num_shared_convs: 4
  num_shared_fcs: 1
  in_channels: 128
  conv_out_channels: 128
  fc_out_channels: 512
  roi_feat_size: 7
  reg_class_agnostic: False
  bbox_coder:
    target_means: [0.0, 0.0, 0.0, 0.0]
    target_stds: [0.1, 0.1, 0.2, 0.2]
  loss_cls:
    loss_weight: 1.0
  loss_bbox:
    beta: 1.0
    loss_weight: 1.0
  norm_cfg:
    type: 'BN'
    momentum: 0.01
    eps: 0.001

mask_head:
  num_convs: 4
  in_channels: 128
  conv_out_channels: 128
  norm_cfg:
    type: 'BN'
    momentum: 0.01
    eps: 0.001
  loss_mask:
    loss_weight: 1.0

# roi_align
roi:
  roi_layer: {type: 'RoIAlign', out_size: 7, sample_num: 2}
  out_channels: 128
  featmap_strides: [8, 16, 32, 64]
  finest_scale: 56
  sample_num: 640

mask_roi:
  roi_layer: {type: 'RoIAlign', out_size: 14, sample_num: 2}
  out_channels: 128
  finest_scale: 56
  featmap_strides: [8, 16, 32, 64]
  sample_num: 128

train_cfg:
  rpn:
    assigner:
      pos_iou_thr: 0.7
      neg_iou_thr: 0.3
      min_pos_iou: 0.3
      match_low_quality: True
    sampler:
      num: 256
      pos_fraction: 0.5
      neg_pos_ub: -1
      add_gt_as_proposals: False
  rpn_proposal:
      nms_pre: 2000
      max_per_img: 2000
      iou_threshold: 0.7
      min_bbox_size: 0
  rcnn:
      assigner:
        pos_iou_thr: 0.5
        neg_iou_thr: 0.5
        min_pos_iou: 0.5
        match_low_quality: True
      sampler:
        num: 512
        pos_fraction: 0.25
        neg_pos_ub: -1
        add_gt_as_proposals: True
      mask_size: 28

test_cfg:
  rpn:
    nms_pre: 1000
    max_per_img: 1000
    iou_threshold: 0.7
    min_bbox_size: 0
  rcnn:
    score_thr: 0.05
    iou_threshold: 0.5
    max_per_img: 100
    mask_thr_binary: 0.5

# optimizer
opt_type: 'sgd'
lr: 0.001
min_lr: 0.0000001
momentum: 0.9
weight_decay: 0.00004
warmup_step: 4000
warmup_ratio: 0.1
lr_steps: [320, 340]
lr_type: 'multistep'
grad_clip: 0


# train
num_gts: 100
batch_size: 6
accumulate_step: 1
test_batch_size: 1
loss_scale: 256
epoch_size: 350
run_eval: 1
eval_every: 1
enable_graph_kernel: 0
finetune: 0
datasink: 0
pre_trained: ''

#distribution training
run_distribute: 0
device_id: 0
device_num: 1
rank_id: 0

# Number of threads used to process the dataset in parallel
num_parallel_workers: 6
# Parallelize Python operations with multiple worker processes
python_multiprocessing: 0
# dataset setting
train_dataset: '/data/coco-2017/train'
val_dataset: '/data/coco-2017/validation/'
coco_classes: ['background', 'person', 'bicycle', 'car', 'motorcycle',
               'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']
num_classes: 81
train_dataset_num: 0
train_dataset_divider: 0

# images
img_width: 640
img_height: 640
mask_divider: 1
ratio_range: [0.5, 2.0]
divider: 64
img_mean: [123.675, 116.28, 103.53]
img_std: [58.395, 57.12, 57.375]
to_rgb: 1
keep_ratio: 1

# augmentation
flip_ratio: 0.5
expand_ratio: 0.0

# callbacks
save_every: 100
keep_checkpoint_max: 5
keep_best_checkpoints_max: 5

---
# Config description for each option
enable_modelarts: 'Whether training on modelarts, default: False'

device_target: 'device where the code will be implemented, default is GPU.'
train_outputs: 'Path for folder with experiments.'
brief: 'Short experiment name, experiment folder will arrive in `train_outputs` folder. `brief` will suffix of experiment folder name.'
img_width: 'Input images weight.'
img_height: 'Input images height.'

lr: 'Base learning rate value.'
batch_size: 'Training batch size.'
pre_trained: 'Path to pretraining model (resume training or train new fine tuned model).'

---
device_target: ['GPU', 'CPU']
mode: ['graph', 'pynative']
